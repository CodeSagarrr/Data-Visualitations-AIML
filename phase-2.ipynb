{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3a1439",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998f1d7",
   "metadata": {},
   "source": [
    "* Data preprocessing ka matlab raw data ko clean, structured aur model-ready form me convert karna. Real world data hamesha messy hota hai, isliye preprocessing karna zaroori hota hai.\n",
    "\n",
    "* Why we use in AIML:\n",
    "\n",
    "    - Machine learning algorithms ko clean aur consistent data chahiye. Agar data me missing values, outliers, unscaled features ya categorical labels ka confusion ho to model galat patterns seekh leta hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42470131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>User Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Date of birth</th>\n",
       "      <th>Job Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>88F7B33d2bcf9f5</td>\n",
       "      <td>Shelby</td>\n",
       "      <td>Terrell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>elijah57@example.net</td>\n",
       "      <td>001-084-906-7849x73518</td>\n",
       "      <td>1945-10-26</td>\n",
       "      <td>Games developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>f90cD3E76f1A9b9</td>\n",
       "      <td>Phillip</td>\n",
       "      <td>Summers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bethany14@example.com</td>\n",
       "      <td>214.112.6044x4913</td>\n",
       "      <td>1910-03-24</td>\n",
       "      <td>Phytotherapist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DbeAb8CcdfeFC2c</td>\n",
       "      <td>Kristine</td>\n",
       "      <td>Travis</td>\n",
       "      <td>Male</td>\n",
       "      <td>bthompson@example.com</td>\n",
       "      <td>277.609.7938</td>\n",
       "      <td>1992-07-02</td>\n",
       "      <td>Homeopath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A31Bee3c201ef58</td>\n",
       "      <td>Yesenia</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>Male</td>\n",
       "      <td>kaitlinkaiser@example.com</td>\n",
       "      <td>584.094.6111</td>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>Market researcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1bA7A3dc874da3c</td>\n",
       "      <td>Lori</td>\n",
       "      <td>Todd</td>\n",
       "      <td>Male</td>\n",
       "      <td>buchananmanuel@example.net</td>\n",
       "      <td>689-207-3558x7233</td>\n",
       "      <td>1938-12-01</td>\n",
       "      <td>Veterinary surgeon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index          User Id First Name Last Name   Sex  \\\n",
       "0      1  88F7B33d2bcf9f5     Shelby   Terrell   NaN   \n",
       "1      2  f90cD3E76f1A9b9    Phillip   Summers   NaN   \n",
       "2      3  DbeAb8CcdfeFC2c   Kristine    Travis  Male   \n",
       "3      4  A31Bee3c201ef58    Yesenia  Martinez  Male   \n",
       "4      5  1bA7A3dc874da3c       Lori      Todd  Male   \n",
       "\n",
       "                        Email                   Phone Date of birth  \\\n",
       "0        elijah57@example.net  001-084-906-7849x73518    1945-10-26   \n",
       "1       bethany14@example.com       214.112.6044x4913    1910-03-24   \n",
       "2       bthompson@example.com            277.609.7938    1992-07-02   \n",
       "3   kaitlinkaiser@example.com            584.094.6111    2017-08-03   \n",
       "4  buchananmanuel@example.net       689-207-3558x7233    1938-12-01   \n",
       "\n",
       "            Job Title  \n",
       "0     Games developer  \n",
       "1      Phytotherapist  \n",
       "2           Homeopath  \n",
       "3   Market researcher  \n",
       "4  Veterinary surgeon  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "# duplicates hata rahe hain taki model redundant rows na sikhe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b9db2",
   "metadata": {},
   "source": [
    "# Train–Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770bf52",
   "metadata": {},
   "source": [
    "* Train-test split technique dataset ko do parts me divide karti hai:\n",
    "\n",
    "    - Training set: Jise model ko pattern sikhane ke liye diya jata hai\n",
    "\n",
    "    - Testing set: Jise unseen data ki tarah treat kiya jata hai, taaki model ki real-world performance jaani ja sake\n",
    "\n",
    "* Agar split nahi karte to model test bhi wahi data pe karega jisme woh trained hua hai, jise overfitting bolte hain.\n",
    "\n",
    "* Why we use: \n",
    "\n",
    "    - Model ka objective real-world unseen data ko predict karna hota hai. Train-test split ensure karta hai ki evaluation fair ho.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc62ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.2)\n",
    "\n",
    "# 20% data testing ke liye rakh rahe hain, taaki unbiased evaluation ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce8bcc",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3031fa9",
   "metadata": {},
   "source": [
    "* Scaling matlab numerical features ko ek common uniform scale me lana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e16421",
   "metadata": {},
   "source": [
    "### (1) StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166669d",
   "metadata": {},
   "source": [
    "* StandardScaler har numeric feature ko aise transform karta hai ki\n",
    "\n",
    "    - mean = 0\n",
    "\n",
    "    - Standard Deviation = 1\n",
    "\n",
    "* Matlab har value represent hoti hai ki woh average se kitna above ya below hai.\n",
    "\n",
    "* Why in AIML:\n",
    "\n",
    "    - Kuch algorithms jaise Logistic Regression, SVM, Neural Networks input magnitude ke liye sensitive hote hain. Agar ek feature km value range me hai aur dusra large me, model biased ho jata hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# features ko standard scale par la rahe hain taki model sabko equal importance de\n",
    "# Age aur Salary ko equal scale par la diya gaya, taaki model unpar fair weight de."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73cc6b6",
   "metadata": {},
   "source": [
    "### (2) MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ceec8b",
   "metadata": {},
   "source": [
    "* MinMaxScaler values ko 0 se 1 ke range me compress karta hai.\n",
    "Formula hota hai: (x - min) / (max - min)\n",
    "\n",
    "* Why in AIML :\n",
    "\n",
    "    - Neural networks, KNN, KMeans jaise algorithms bounded range me ache kaam karte hain. Yeh scaling outliers ka impact bhi kam karti hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# values ko 0-1 range me normalize kar rahe hain taaki training stable \n",
    "# Har value 0-1 range me aa gayi, model training smooth ho gayi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c5afe",
   "metadata": {},
   "source": [
    "# Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367f3df",
   "metadata": {},
   "source": [
    "### a) OneHot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcdb7b0",
   "metadata": {},
   "source": [
    "* OneHot categorical text ko multiple binary columns me convert karta hai.\n",
    "Har category ka ek column hota hai jisme 0/1 represent hota hai.\n",
    "\n",
    "* Why in AIML:\n",
    "\n",
    "    - ML algorithms text nahi samajh sakte. OneHot ensure karta hai ki categories ke beech koi fake order assume na ho.\n",
    "\n",
    "* Runnable Example:\n",
    "    - Upar python me dummies nahi chalaya, lekin concept wahi hai.\n",
    "\n",
    "* Comment:\n",
    "\n",
    "    - Gender = Male, Female ko numeric binary form me convert kar sakte ho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78168b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['Sex'])\n",
    "# Gender column ko binary columns me convert kar rahe hain (Male, Female)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2f969",
   "metadata": {},
   "source": [
    "### b) Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20752d1e",
   "metadata": {},
   "source": [
    "* LabelEncoder har category ko ek unique integer assign karta hai. Ye simple aur efficient hota hai, but categories me order introduce kar deta hai.\n",
    "\n",
    "* Why in AIML:\n",
    "\n",
    "    - Tree-based algorithms (Decision Tree, RandomForest, XGBoost) order se affect nahi hote, isliye label encoding perfect hoti hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['City'] = le.fit_transform(df['City'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa211f2e",
   "metadata": {},
   "source": [
    "# Outlier Detection Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d758d7",
   "metadata": {},
   "source": [
    "* Outliers wo values hoti hain jo baaki values se extreme difference rakhti hain.\n",
    "\n",
    "* Example: Salary column me 700000 ek clear outlier hai.\n",
    "\n",
    "* Agar unhe detect ya fix nahi karte, to model un values ko priority se learn karne lagta hai.\n",
    "\n",
    "* Common methods:\n",
    "\n",
    "    - Z score\n",
    "\n",
    "    - IQR method\n",
    "\n",
    "    - Boxplot visualization\n",
    "\n",
    "* Why in AIML:\n",
    "\n",
    "    - Outliers training ko unstable bana dete hain. Regression models me toh performance heavily degrade hota hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Salary'].quantile(0.25)\n",
    "Q3 = df['Salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df[(df['Salary'] < Q1 - 1.5 * IQR) | (df['Salary'] > Q3 + 1.5 * IQR)]\n",
    "# IQR method se extreme salary values detect kar rahe hain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98a90a",
   "metadata": {},
   "source": [
    "# Pipeline Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ff5ff",
   "metadata": {},
   "source": [
    "* Pipeline ek combined workflow hota hai jisme preprocessing + model training ek sequence me hota hai.\n",
    "Tum steps ko chain kar sakte ho jaise:\n",
    "\n",
    "* scaling → encoding → model\n",
    "\n",
    "* Why in AIML:\n",
    "\n",
    "    - Data leakage avoid hota hai\n",
    "\n",
    "    - Train/test dono me same transformation apply hota hai\n",
    "\n",
    "    - Code clean and maintainable hota hai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da709899",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01780969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filled_df':     Age  Salary   Gender     City  City_encoded\n",
       " 0  25.0   50000     Male   Mumbai             2\n",
       " 1  30.0   60000   Female    Delhi             1\n",
       " 2  26.5   55000   Female   Mumbai             2\n",
       " 3  22.0  700000  Unknown  Chennai             0\n",
       " 4  28.0   58000     Male    Delhi             1,\n",
       " 'train_test_shapes': ((4, 2), (1, 2)),\n",
       " 'standard_scaled': array([[-0.47918636, -0.52226814],\n",
       "        [ 1.36383809, -0.48346664],\n",
       "        [ 0.07372098, -0.50286739],\n",
       "        [-1.58500103,  1.99982911],\n",
       "        [ 0.62662831, -0.49122694]]),\n",
       " 'minmax_scaled': array([[0.375     , 0.        ],\n",
       "        [1.        , 0.01538462],\n",
       "        [0.5625    , 0.00769231],\n",
       "        [0.        , 1.        ],\n",
       "        [0.75      , 0.01230769]]),\n",
       " 'label_encoded':       City  City_encoded\n",
       " 0   Mumbai             2\n",
       " 1    Delhi             1\n",
       " 2   Mumbai             2\n",
       " 3  Chennai             0\n",
       " 4    Delhi             1,\n",
       " 'outliers':     Age  Salary   Gender     City  City_encoded\n",
       " 3  22.0  700000  Unknown  Chennai             0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset\n",
    "df = pd.DataFrame({\n",
    "    \"Age\": [25, 30, None, 22, 28],\n",
    "    \"Salary\": [50000, 60000, 55000, 700000, 58000],  # contains an outlier (700000)\n",
    "    \"Gender\": [\"Male\", \"Female\", \"Female\", None, \"Male\"],\n",
    "    \"City\": [\"Mumbai\", \"Delhi\", \"Mumbai\", \"Chennai\", \"Delhi\"]\n",
    "})\n",
    "\n",
    "output = {}\n",
    "\n",
    "# Handling Missing Values\n",
    "df_filled = df.copy()\n",
    "df_filled[\"Age\"] = df_filled[\"Age\"].fillna(df_filled[\"Age\"].median())\n",
    "df_filled[\"Gender\"] = df_filled[\"Gender\"].fillna(\"Unknown\")\n",
    "output[\"filled_df\"] = df_filled\n",
    "\n",
    "# Train-test split\n",
    "X = df_filled[[\"Age\", \"Salary\"]]\n",
    "y = df_filled[\"City\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "output[\"train_test_shapes\"] = (X_train.shape, X_test.shape)\n",
    "\n",
    "# StandardScaler\n",
    "scaler_std = StandardScaler()\n",
    "X_std = scaler_std.fit_transform(X)\n",
    "output[\"standard_scaled\"] = X_std\n",
    "\n",
    "\n",
    "# MinMaxScaler\n",
    "scaler_mm = MinMaxScaler()\n",
    "X_mm = scaler_mm.fit_transform(X)\n",
    "output[\"minmax_scaled\"] = X_mm\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "df_filled[\"City_encoded\"] = le.fit_transform(df_filled[\"City\"])\n",
    "output[\"label_encoded\"] = df_filled[[\"City\", \"City_encoded\"]]\n",
    "\n",
    "\n",
    "# Outlier detection using IQR\n",
    "Q1 = df_filled[\"Salary\"].quantile(0.25)\n",
    "Q3 = df_filled[\"Salary\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df_filled[(df_filled[\"Salary\"] < Q1 - 1.5 * IQR) |\n",
    "                     (df_filled[\"Salary\"] > Q3 + 1.5 * IQR)]\n",
    "output[\"outliers\"] = outliers\n",
    "\n",
    "output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
